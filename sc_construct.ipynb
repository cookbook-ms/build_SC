{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/maosheng/Library/CloudStorage/OneDrive-DelftUniversityofTechnology/build_SC\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "import os\n",
    "from itertools import groupby\n",
    "from math import floor\n",
    "print(os. getcwd() )\n",
    "import numpy as np\n",
    "import scipy.sparse as sp \n",
    "from scipy.sparse import coo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def generate_simplices(top_dim=7, file_path='./ScHoLP-Data-1.0/', file_name='email-Enron',unique_simplices=False,percentage_time=1):\n",
    "    '''\n",
    "    top_dim: the largest simplicial order, i.e., the simplicial complex order\n",
    "    file_name: \n",
    "    unique_simplices: if to generate the unique simplices, since this dataset contains the same simplex for many times over a certain length of time stamps\n",
    "        - 'True': we also include the duration of the time stamps of each simplex in the dict value\n",
    "        - 'False': generate simplices allowed to be duplicate        \n",
    "    '''\n",
    "    file_path = file_path +file_name\n",
    "    with open(file_path+'/'+file_name+'-nverts.txt') as f:\n",
    "        simplex_dim = [line.rstrip('\\n') for line in f]    \n",
    "    with open(file_path+'/'+file_name+'-simplices.txt') as f:\n",
    "        simplex_vertices = [line.rstrip('\\n') for line in f]\n",
    "    top_dim = top_dim+1\n",
    "    simplex_dim = simplex_dim[:floor(percentage_time*len(simplex_dim))]\n",
    "    start=0\n",
    "    simplex_vertices_tupled = []\n",
    "    for count in simplex_dim:\n",
    "        end = start + int(count) \n",
    "        simplex_set = simplex_vertices[start:end]\n",
    "        simplex_set = {int(x) for x in simplex_set}\n",
    "        simplex_vertices_tupled.append(simplex_set)\n",
    "        start=end\n",
    "    \n",
    "    list_simplices = [None]*top_dim\n",
    "    cochains = [None]*top_dim\n",
    "    for k in range(top_dim):\n",
    "        list_simplices[k] = [(sorted(id_vertices)) for id_simp,id_vertices in enumerate(simplex_vertices_tupled) if len(id_vertices) == k+1]\n",
    "        list_simplices[k].sort() \n",
    "        freq_simplices = [len(list(group)) for key, group in groupby(list_simplices[k])]\n",
    "        if unique_simplices:\n",
    "            # list_simplices[k]=[list(x) for x in set(tuple(x) for x in list_simplices[k])]\n",
    "            sorted_list = list_simplices[k].copy() \n",
    "            sorted_list = sorted(sorted_list)\n",
    "            sorted_list = [frozenset(l) for l in sorted_list]\n",
    "            unique_sets = list(OrderedDict.fromkeys(map(frozenset, sorted_list)).keys())\n",
    "            '''list_simplices[k]:{'key':idx,'value':{v0,v1,...,v_k},...}'''\n",
    "            list_simplices[k] = dict(zip(unique_sets,range(len(list_simplices[k]))))\n",
    "            cochains[k] = dict(zip(unique_sets,freq_simplices))\n",
    "            \n",
    "        else:\n",
    "            sorted_list = list_simplices[k].copy() \n",
    "            sorted_list = sorted(sorted_list,key=tuple)   \n",
    "            sorted_list = [frozenset(l) for l in sorted_list]\n",
    "            list_simplices[k] = dict(zip(sorted_list,range(len(list_simplices[k]))))\n",
    "    \n",
    "    return list_simplices,cochains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './ScHoLP-Data-1.0/'\n",
    "file_name = 'email-Enron'#'tags-stack-overflow'#'email-Enron'#'contact-high-school'##\n",
    "list_simp,cochains_dic = generate_simplices(top_dim=5,file_path=file_path,file_name=file_name,unique_simplices=True,percentage_time=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317\n",
      "{frozenset({2}): 0, frozenset({3}): 1, frozenset({6}): 2, frozenset({8}): 3, frozenset({12}): 4, frozenset({13}): 5, frozenset({15}): 6, frozenset({17}): 7, frozenset({19}): 8, frozenset({20}): 9, frozenset({21}): 10, frozenset({23}): 11, frozenset({29}): 12, frozenset({30}): 13, frozenset({33}): 14, frozenset({37}): 15, frozenset({41}): 16, frozenset({42}): 17, frozenset({43}): 18, frozenset({44}): 19, frozenset({46}): 20, frozenset({47}): 21, frozenset({55}): 22, frozenset({56}): 23, frozenset({57}): 24, frozenset({61}): 25, frozenset({62}): 26, frozenset({63}): 27, frozenset({65}): 28, frozenset({68}): 29, frozenset({70}): 30, frozenset({73}): 31, frozenset({74}): 32, frozenset({77}): 33, frozenset({83}): 34, frozenset({86}): 35, frozenset({90}): 36, frozenset({95}): 37, frozenset({96}): 38, frozenset({102}): 39, frozenset({104}): 40, frozenset({108}): 41, frozenset({110}): 42, frozenset({111}): 43, frozenset({112}): 44, frozenset({114}): 45, frozenset({115}): 46, frozenset({120}): 47, frozenset({131}): 48, frozenset({132}): 49, frozenset({134}): 50, frozenset({139}): 51, frozenset({143}): 52, frozenset({144}): 53, frozenset({146}): 54}\n"
     ]
    }
   ],
   "source": [
    "print(len(cochains_dic[2]))\n",
    "print(list_simp[0])\n",
    "# print(cochains_dic[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''add the missed ndoes in the list based on edge list'''\n",
    "def fix_nodes(list_simplices,cochains):\n",
    "    list_nodes, idx_nodes = [],[]\n",
    "    freq_nodes = []\n",
    "    for simplex, idx_simplex in list_simplices[1].items():\n",
    "        for i, node in enumerate(np.sort(list(simplex))):\n",
    "            list_nodes.append(node)\n",
    "        \n",
    "    list_nodes = (list(set(list_nodes)))\n",
    "    list_nodes = [frozenset([l]) for l in list_nodes]\n",
    "    freq_nodes = [0]*len(list_nodes)\n",
    "    freq_nodes = [cochains[0][l] if l in cochains[0] else 0 for l in list_nodes]\n",
    "    list_simplices[0] = dict(zip(list_nodes,range(len(list_nodes))))\n",
    "    cochains[0] = dict(zip(list_nodes,freq_nodes)) \n",
    "        \n",
    "    return list_simplices,cochains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "809\n",
      "{frozenset({1}): 0, frozenset({2}): 1, frozenset({3}): 2, frozenset({4}): 3, frozenset({5}): 4, frozenset({6}): 5, frozenset({7}): 6, frozenset({8}): 7, frozenset({9}): 8, frozenset({11}): 9, frozenset({12}): 10, frozenset({13}): 11, frozenset({14}): 12, frozenset({15}): 13, frozenset({17}): 14, frozenset({18}): 15, frozenset({19}): 16, frozenset({20}): 17, frozenset({21}): 18, frozenset({22}): 19, frozenset({23}): 20, frozenset({24}): 21, frozenset({25}): 22, frozenset({26}): 23, frozenset({27}): 24, frozenset({28}): 25, frozenset({29}): 26, frozenset({30}): 27, frozenset({32}): 28, frozenset({33}): 29, frozenset({34}): 30, frozenset({36}): 31, frozenset({37}): 32, frozenset({38}): 33, frozenset({39}): 34, frozenset({40}): 35, frozenset({41}): 36, frozenset({42}): 37, frozenset({43}): 38, frozenset({44}): 39, frozenset({45}): 40, frozenset({46}): 41, frozenset({47}): 42, frozenset({48}): 43, frozenset({50}): 44, frozenset({51}): 45, frozenset({52}): 46, frozenset({53}): 47, frozenset({54}): 48, frozenset({55}): 49, frozenset({56}): 50, frozenset({57}): 51, frozenset({58}): 52, frozenset({59}): 53, frozenset({60}): 54, frozenset({61}): 55, frozenset({62}): 56, frozenset({63}): 57, frozenset({64}): 58, frozenset({65}): 59, frozenset({66}): 60, frozenset({67}): 61, frozenset({68}): 62, frozenset({69}): 63, frozenset({70}): 64, frozenset({71}): 65, frozenset({72}): 66, frozenset({73}): 67, frozenset({74}): 68, frozenset({75}): 69, frozenset({76}): 70, frozenset({77}): 71, frozenset({78}): 72, frozenset({79}): 73, frozenset({80}): 74, frozenset({81}): 75, frozenset({82}): 76, frozenset({83}): 77, frozenset({84}): 78, frozenset({85}): 79, frozenset({86}): 80, frozenset({87}): 81, frozenset({88}): 82, frozenset({89}): 83, frozenset({90}): 84, frozenset({91}): 85, frozenset({92}): 86, frozenset({93}): 87, frozenset({94}): 88, frozenset({95}): 89, frozenset({96}): 90, frozenset({97}): 91, frozenset({98}): 92, frozenset({99}): 93, frozenset({100}): 94, frozenset({101}): 95, frozenset({102}): 96, frozenset({103}): 97, frozenset({104}): 98, frozenset({105}): 99, frozenset({106}): 100, frozenset({107}): 101, frozenset({108}): 102, frozenset({109}): 103, frozenset({110}): 104, frozenset({111}): 105, frozenset({112}): 106, frozenset({113}): 107, frozenset({114}): 108, frozenset({115}): 109, frozenset({116}): 110, frozenset({117}): 111, frozenset({118}): 112, frozenset({119}): 113, frozenset({120}): 114, frozenset({121}): 115, frozenset({122}): 116, frozenset({123}): 117, frozenset({125}): 118, frozenset({126}): 119, frozenset({127}): 120, frozenset({128}): 121, frozenset({129}): 122, frozenset({130}): 123, frozenset({131}): 124, frozenset({132}): 125, frozenset({133}): 126, frozenset({134}): 127, frozenset({135}): 128, frozenset({136}): 129, frozenset({137}): 130, frozenset({138}): 131, frozenset({139}): 132, frozenset({140}): 133, frozenset({141}): 134, frozenset({142}): 135, frozenset({143}): 136, frozenset({144}): 137, frozenset({145}): 138, frozenset({146}): 139, frozenset({147}): 140, frozenset({148}): 141}\n"
     ]
    }
   ],
   "source": [
    "list_simp,cochains_dic = fix_nodes(list_simp,cochains_dic)\n",
    "print(len(cochains_dic[1]))\n",
    "print((list_simp[0]))\n",
    "# print(list_simp[1])\n",
    "# print(cochains_dic[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_incidence_matrix(simplices):\n",
    "    boundaries = list()\n",
    "    for d in range(1, len(simplices)):\n",
    "        # print(d)\n",
    "        idx_simplices, idx_faces, values = [], [], []\n",
    "        for simplex, idx_simplex in simplices[d].items():\n",
    "            for i, left_out in enumerate(np.sort(list(simplex))):\n",
    "                face = simplex.difference({left_out})\n",
    "                if face in simplices[d-1]:\n",
    "                    idx_simplices.append(idx_simplex)\n",
    "                    values.append((-1)**i)\n",
    "                    # print(idx_simplex,left_out,face)\n",
    "                    idx_faces.append(simplices[d-1][face]) \n",
    "        # assert len(values) == (d+1) * len(simplices[d])\n",
    "        boundary = coo_matrix((values, (idx_faces, idx_simplices)),\n",
    "                                     dtype=np.float32,\n",
    "                                     shape=(len(simplices[d-1]), len(simplices[d])))\n",
    "        boundaries.append(boundary)\n",
    "    return boundaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142, 809) (809, 317) (317, 138) (138, 63)\n",
      "  (64, 0)\t1.0\n",
      "  (6, 0)\t-1.0\n",
      "  (1, 0)\t1.0\n",
      "  (198, 1)\t1.0\n",
      "  (3, 1)\t1.0\n",
      "  (220, 2)\t1.0\n",
      "  (15, 2)\t-1.0\n",
      "  (4, 2)\t1.0\n",
      "  (232, 3)\t1.0\n",
      "  (27, 3)\t-1.0\n",
      "  (4, 3)\t1.0\n",
      "  (283, 4)\t1.0\n",
      "  (6, 4)\t-1.0\n",
      "  (5, 4)\t1.0\n",
      "  (22, 5)\t-1.0\n",
      "  (5, 5)\t1.0\n",
      "  (365, 6)\t1.0\n",
      "  (7, 6)\t-1.0\n",
      "  (6, 6)\t1.0\n",
      "  (369, 7)\t1.0\n",
      "  (10, 7)\t-1.0\n",
      "  (6, 7)\t1.0\n",
      "  (371, 8)\t1.0\n",
      "  (12, 8)\t-1.0\n",
      "  (6, 8)\t1.0\n",
      "  :\t:\n",
      "  (704, 306)\t1.0\n",
      "  (741, 307)\t1.0\n",
      "  (713, 307)\t1.0\n",
      "  (713, 308)\t1.0\n",
      "  (756, 309)\t1.0\n",
      "  (745, 309)\t-1.0\n",
      "  (741, 309)\t1.0\n",
      "  (771, 310)\t1.0\n",
      "  (745, 310)\t-1.0\n",
      "  (742, 310)\t1.0\n",
      "  (758, 311)\t1.0\n",
      "  (747, 311)\t-1.0\n",
      "  (771, 312)\t1.0\n",
      "  (756, 312)\t-1.0\n",
      "  (754, 312)\t1.0\n",
      "  (755, 313)\t-1.0\n",
      "  (799, 314)\t1.0\n",
      "  (760, 314)\t-1.0\n",
      "  (759, 314)\t1.0\n",
      "  (804, 315)\t1.0\n",
      "  (773, 315)\t-1.0\n",
      "  (772, 315)\t1.0\n",
      "  (802, 316)\t1.0\n",
      "  (792, 316)\t-1.0\n",
      "  (791, 316)\t1.0\n"
     ]
    }
   ],
   "source": [
    "boundaries = get_incidence_matrix(list_simp)\n",
    "b1,b2,b3,b4 = boundaries[0],boundaries[1],boundaries[2],boundaries[3]\n",
    "# np.save(file_path+file_name+'/'+file_name+'_cochains_all.npy', cochains_dic)\n",
    "# np.save(file_path+file_name+'/'+file_name+'_boundaries_all.npy', boundaries)\n",
    "print(b1.shape,b2.shape,b3.shape,b4.shape)\n",
    "\n",
    "tri_pos_neg_idx = [b2.getcol(j).nnz==3 for j in range(b2.shape[1])]\n",
    "# print(tri_pos_neg_idx)\n",
    "b2_pos = b2.toarray()[:,tri_pos_neg_idx]\n",
    "print(b2)\n",
    "# print(b2_pos.shape)\n",
    "# print(np.nonzero(b1@b2))\n",
    "# print(np.count_nonzero(b1@b2_pos))\n",
    "# print(cochains_dic[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_boundaries_positive_simplices(boundaries,cochains_dic):\n",
    "    boundaries_pos_simplices = []\n",
    "    cochains_dic =[np.array(list(cochains_dic[i].values())) for i in range(len(cochains_dic))]\n",
    "    boundaries = [boundaries[k].toarray() for k in range(len(boundaries))]\n",
    "    cochains = []\n",
    "    cochains.append(cochains_dic[0])\n",
    "    for k in range(len(boundaries)-1):\n",
    "        bk = boundaries[k]\n",
    "        pos_neg_idx = [np.count_nonzero(bk[:,j])==k+2 for j in range(bk.shape[1])]\n",
    "        bk_pos = bk[:,pos_neg_idx]\n",
    "        boundaries[k+1] = boundaries[k+1][pos_neg_idx,:]\n",
    "        boundaries_pos_simplices.append(bk_pos)\n",
    "        cochains.append(cochains_dic[k+1][pos_neg_idx])\n",
    "        \n",
    "    assert [np.count_nonzero(boundaries_pos_simplices[k]@boundaries_pos_simplices[k+1]) == 0 for k in range(len(boundaries_pos_simplices)-1)]\n",
    "    boundaries_pos_simplices = [coo_matrix(boundaries_pos_simplices[k]) for k in range(len(boundaries_pos_simplices)) ]\n",
    "    return boundaries_pos_simplices,cochains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(142, 809), (809, 191), (191, 7), (7, 0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/numpy/core/_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "# print(cochains_dic[2])\n",
    "boundaries_pos,cochains = build_boundaries_positive_simplices(boundaries,cochains_dic)\n",
    "print([boundaries_pos[k].shape for k in range(len(boundaries_pos))])\n",
    "b1,b2,b3,b4 = boundaries_pos[0],boundaries_pos[1],boundaries_pos[2],boundaries_pos[3]\n",
    "edge_idx = np.reshape(np.nonzero(b2.T)[1],(-1,3)) \n",
    "node_idx = np.reshape(np.nonzero(b1.T)[1],(-1,2))\n",
    "np.save(file_path+file_name+'/'+file_name+'_cochains.npy', cochains)\n",
    "np.save(file_path+file_name+'/'+file_name+'_boundaries.npy', boundaries_pos)\n",
    "# print(len(np.where(cochains[2]>1)[0]))\n",
    "# print(cochains[2])\n",
    "# np.savetxt(file_path+file_name+'/'+file_name+'_cochains'+str(0)+'.txt', cochains[0],delimiter=',',fmt='%.2f')\n",
    "# np.savetxt(file_path+file_name+'/'+file_name+'_cochains'+str(1)+'.txt', cochains[1],delimiter=',',fmt='%.2f')\n",
    "# np.savetxt(file_path+file_name+'/'+file_name+'_cochains'+str(2)+'.txt', cochains[2],delimiter=',',fmt='%.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5z/fws8dk9s1fj2b4thgg65kc0w0000gn/T/ipykernel_54612/2109568865.py:19: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  rayleigh1 /= cochains[dim].T @ cochains[dim]\n",
      "/var/folders/5z/fws8dk9s1fj2b4thgg65kc0w0000gn/T/ipykernel_54612/2109568865.py:20: RuntimeWarning: invalid value encountered in true_divide\n",
      "  fourier1 = eigenvectors.T @ (cochains[dim] / np.linalg.norm(cochains[dim], axis=0))\n",
      "/var/folders/5z/fws8dk9s1fj2b4thgg65kc0w0000gn/T/ipykernel_54612/2109568865.py:19: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  rayleigh1 /= cochains[dim].T @ cochains[dim]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.442922374429223\n",
      "nan\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_laplacians(boundaries):\n",
    "    laplacians = list()\n",
    "    up = coo_matrix(boundaries[0] @ boundaries[0].T)\n",
    "    laplacians.append(up)\n",
    "    for d in range(len(boundaries)-1):\n",
    "        down = boundaries[d].T @ boundaries[d]\n",
    "        up = boundaries[d+1] @ boundaries[d+1].T\n",
    "        laplacians.append(coo_matrix(down + up))\n",
    "    down = boundaries[-1].T @ boundaries[-1]\n",
    "    laplacians.append(coo_matrix(down))\n",
    "    return laplacians\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "laplacians = build_laplacians(boundaries_pos)\n",
    "# measure the signal variation \n",
    "for dim in range(3):\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(laplacians[dim].toarray())\n",
    "    rayleigh1 = cochains[dim].T @ laplacians[dim] @ cochains[dim]\n",
    "    rayleigh1 /= cochains[dim].T @ cochains[dim]\n",
    "    fourier1 = eigenvectors.T @ (cochains[dim] / np.linalg.norm(cochains[dim], axis=0))\n",
    "    print(rayleigh1)\n",
    "    plt.semilogy(eigenvalues[:], np.abs(fourier1)[:], '.', alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(abs(b1).toarray().sum(axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
